{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## As discussed in the report we need to discard bad examples. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import glob\n",
    "import shutil\n",
    "\n",
    "def check_and_discard_data(data_dir , dump_dir):\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        list_of_files_of_single_class = glob.glob(os.path.join(data_dir , class_name , '*')  )  \n",
    "        for file_name in list_of_files_of_single_class:\n",
    "            if file_name.lower().endswith(( '.jpg', '.jpeg')):\n",
    "                try:\n",
    "                    img=Image.open(file_name)\n",
    "                    img.verify()\n",
    "                    height , width = img.size\n",
    "                    if height < 80 or width < 80:\n",
    "                        print('dim less')\n",
    "                        shutil.move(file_name, dump_dir)\n",
    "                except(IOError,SyntaxError)as e:\n",
    "                    print('io error')\n",
    "                    shutil.move(file_name, dump_dir)\n",
    "            else:\n",
    "                print('print other format')\n",
    "                shutil.move( file_name , dump_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_and_discard_data('nsfw_datset' , 'dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16864"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(os.listdir('dump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spliting the datset into train , test , validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mnumpy\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mnp\u001b[39;49;00m\r\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mshutil\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[37m# # Creating Train / Val / Test folders (One time use)\u001b[39;49;00m\r\n",
      "\r\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32msplit_dataset_one_time\u001b[39;49;00m(root_dir , valid_size, test_size , train_path , valid_path , test_path):\r\n",
      "    \r\n",
      "\r\n",
      "    class_names = os.listdir(root_dir)\r\n",
      "\r\n",
      "    \u001b[37m#print(class_names)\u001b[39;49;00m\r\n",
      "    \u001b[34mfor\u001b[39;49;00m single_class \u001b[35min\u001b[39;49;00m class_names:\r\n",
      "        \u001b[34mtry\u001b[39;49;00m :\r\n",
      "\r\n",
      "\r\n",
      "            os.makedirs(os.path.join( train_path , single_class))\r\n",
      "            os.makedirs(os.path.join( valid_path , single_class))\r\n",
      "            os.makedirs(os.path.join( test_path , single_class))\r\n",
      "\r\n",
      "\r\n",
      "            train_single_path = os.path.join( train_path , single_class)\r\n",
      "            test_single_path = os.path.join( test_path , single_class)\r\n",
      "            valid_single_path = os.path.join( valid_path , single_class)\r\n",
      "        \u001b[34mexcept\u001b[39;49;00m FileExistsError:\r\n",
      "            \u001b[34mpass\u001b[39;49;00m\r\n",
      "        \r\n",
      "        single_full_list = os.listdir(os.path.join(root_dir , single_class))\r\n",
      "        \u001b[37m#print(single_full_list[0])\u001b[39;49;00m\r\n",
      "\r\n",
      "        num_examples_per_class = \u001b[36mlen\u001b[39;49;00m(single_full_list)\r\n",
      "        indices = \u001b[36mlist\u001b[39;49;00m(\u001b[36mrange\u001b[39;49;00m(num_examples_per_class))\r\n",
      "        split_valid = \u001b[36mint\u001b[39;49;00m(np.floor(valid_size * num_examples_per_class))\r\n",
      "        split_test = \u001b[36mint\u001b[39;49;00m(np.floor(test_size * num_examples_per_class)) + split_valid\r\n",
      "        np.random.shuffle(indices)\r\n",
      "        train_idx, valid_idx , test_idx = indices[split_test:], indices[:split_valid] , indices[split_valid:split_test]\r\n",
      "\r\n",
      "        \u001b[37m#print(train_idx[:5])\u001b[39;49;00m\r\n",
      "        single_full_list_np = np.array(single_full_list)\r\n",
      "        train_list , valid_list , test_list = single_full_list_np[train_idx].tolist() , single_full_list_np[valid_idx].tolist() , single_full_list_np[test_idx].tolist()\r\n",
      "\r\n",
      "        \u001b[37m#print(len(train_list) , len(valid_list) , len(test_list) , len(single_full_list))\u001b[39;49;00m\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "        \u001b[34mfor\u001b[39;49;00m name \u001b[35min\u001b[39;49;00m train_list:\r\n",
      "            \u001b[37m#print(os.path.join(root_dir , single_class , name) , train_single_path)\u001b[39;49;00m\r\n",
      "            shutil.move( os.path.join(root_dir , single_class , name) , train_single_path)\r\n",
      "\r\n",
      "        \u001b[34mfor\u001b[39;49;00m name \u001b[35min\u001b[39;49;00m valid_list:\r\n",
      "            \u001b[37m#print(os.path.join(root_dir , single_class , name) , valid_single_path)\u001b[39;49;00m\r\n",
      "            shutil.move(os.path.join(root_dir , single_class , name) ,valid_single_path)\r\n",
      "\r\n",
      "        \u001b[34mfor\u001b[39;49;00m name \u001b[35min\u001b[39;49;00m test_list:\r\n",
      "            \u001b[37m#print(os.path.join(root_dir , single_class , name) , test_single_path)\u001b[39;49;00m\r\n",
      "            shutil.move(os.path.join(root_dir , single_class , name), test_single_path)\r\n"
     ]
    }
   ],
   "source": [
    "!pygmentize useful_scripts/useful_scripts/split_dataset.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from useful_scripts.useful_scripts.split_dataset import split_dataset_one_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataset_one_time('nsfw_datset' , 0.075 ,0.075 , 'nsfw_dataset_train' , 'nsfw_dataset_valid' , 'nsfw_dataset_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the im2rec tool in the machine. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: IM2REC=/home/ec2-user/anaconda3/envs/amazonei_mxnet_p36/lib/python3.6/site-packages/mxnet/tools/im2rec.py\n"
     ]
    }
   ],
   "source": [
    "import sys,os\n",
    "\n",
    "suffix='/mxnet/tools/im2rec.py'\n",
    "im2rec = list(filter( (lambda x: os.path.isfile(x + suffix )), sys.path))[0] + suffix\n",
    "%env IM2REC=$im2rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We need to create .lst file before creating .rec file Notice That test_ratio is kept at 0.0 because we have already split the dataset. Also The --resize is set 224 because image classification algorithm accepts image size (224,224)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LST files\n",
      "Label classes:\n",
      "animated 0\n",
      "nude 1\n",
      "porn 2\n",
      "safe_for_work 3\n",
      "semi_nude 4\n",
      "Creating RecordIO files\n",
      "Creating .rec file from /home/ec2-user/SageMaker/nsfw_dataset_valid.lst in /home/ec2-user/SageMaker\n",
      "time: 0.3074500560760498  count: 0\n",
      "time: 28.615877151489258  count: 1000\n",
      "time: 29.252779245376587  count: 2000\n",
      "time: 27.263898849487305  count: 3000\n",
      "time: 24.09006953239441  count: 4000\n",
      "time: 24.43202519416809  count: 5000\n",
      "time: 23.392404556274414  count: 6000\n",
      "time: 22.804959058761597  count: 7000\n",
      "time: 23.166723251342773  count: 8000\n",
      "time: 21.34347176551819  count: 9000\n",
      "time: 20.13561248779297  count: 10000\n",
      "time: 20.357985973358154  count: 11000\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 387M Sep 11 18:49 nsfw_dataset_test.rec\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 318M Sep 12 07:16 nsfw_dataset_valid.rec\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"Creating LST files\"\n",
    "python $IM2REC --list --recursive --pass-through --test-ratio=0.0 --train-ratio=1.0 nsfw_dataset_valid nsfw_dataset_valid > nsfw_dataset_valid_classes\n",
    "\n",
    "echo \"Label classes:\"\n",
    "cat nsfw_dataset_valid_classes\n",
    "\n",
    "echo \"Creating RecordIO files\"\n",
    "python $IM2REC --num-thread=4 nsfw_dataset_valid.lst nsfw_dataset_valid/ --resize=224\n",
    "#python $IM2REC --num-thread=4 ${DATASET_NAME}_test.lst $DATASET_NAME\n",
    "ls -lh *.rec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## upload the .rec file to s3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./nsfw_dataset_valid.rec to s3://project-completion-udacity/nsfw_dataset/validation/nsfw_dataset_valid.rec\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp nsfw_dataset_valid.rec s3://project-completion-udacity/nsfw_dataset/validation/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We did for validation. Now doing for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LST files\n",
      "Label classes:\n",
      "animated 0\n",
      "nude 1\n",
      "porn 2\n",
      "safe_for_work 3\n",
      "semi_nude 4\n",
      "Creating RecordIO files\n",
      "Creating .rec file from /home/ec2-user/SageMaker/nsfw_dataset_test.lst in /home/ec2-user/SageMaker\n",
      "time: 0.05958127975463867  count: 0\n",
      "time: 9.245877742767334  count: 1000\n",
      "time: 7.712120532989502  count: 2000\n",
      "time: 7.699880361557007  count: 3000\n",
      "time: 9.303281545639038  count: 4000\n",
      "time: 9.592679262161255  count: 5000\n",
      "time: 8.724056959152222  count: 6000\n",
      "time: 8.638715028762817  count: 7000\n",
      "time: 10.148676872253418  count: 8000\n",
      "time: 7.879869699478149  count: 9000\n",
      "time: 7.991632699966431  count: 10000\n",
      "time: 8.284252405166626  count: 11000\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 387M Sep 11 18:49 nsfw_dataset_test.rec\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 388M Sep 11 18:46 nsfw_dataset_valid.rec\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"Creating LST files\"\n",
    "python $IM2REC --list --recursive --pass-through --test-ratio=0.0 --train-ratio=1.0 nsfw_dataset_test nsfw_dataset_test > nsfw_dataset_test_classes\n",
    "\n",
    "echo \"Label classes:\"\n",
    "cat nsfw_dataset_test_classes\n",
    "\n",
    "echo \"Creating RecordIO files\"\n",
    "python $IM2REC --num-thread=4 nsfw_dataset_test.lst nsfw_dataset_test/ --resize=256\n",
    "#python $IM2REC --num-thread=4 ${DATASET_NAME}_test.lst $DATASET_NAME\n",
    "ls -lh *.rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./nsfw_dataset_test.rec to s3://project-completion-udacity/nsfw_dataset/testing/nsfw_dataset_test.rec\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp nsfw_dataset_test.rec s3://project-completion-udacity/nsfw_dataset/testing/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarly doing this training ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating LST files\n",
      "Label classes:\n",
      "animated 0\n",
      "nude 1\n",
      "porn 2\n",
      "safe_for_work 3\n",
      "semi_nude 4\n",
      "Creating RecordIO files\n",
      "Creating .rec file from /home/ec2-user/SageMaker/nsfw_dataset_train.lst in /home/ec2-user/SageMaker\n",
      "imread read blank (None) image for file: /home/ec2-user/SageMaker/nsfw_dataset_train/porn/le8LkPs.jpg\n",
      "time: 0.046601057052612305  count: 0\n",
      "time: 18.696394205093384  count: 1000\n",
      "time: 17.1350200176239  count: 2000\n",
      "time: 17.429579734802246  count: 3000\n",
      "time: 15.988012313842773  count: 4000\n",
      "time: 15.514463901519775  count: 5000\n",
      "time: 16.88562774658203  count: 6000\n",
      "time: 14.923904657363892  count: 7000\n",
      "time: 15.456107378005981  count: 8000\n",
      "time: 14.62105655670166  count: 9000\n",
      "time: 15.861175060272217  count: 10000\n",
      "time: 12.652273893356323  count: 11000\n",
      "time: 12.256561517715454  count: 12000\n",
      "time: 15.415345668792725  count: 13000\n",
      "time: 12.36422848701477  count: 14000\n",
      "time: 13.456058979034424  count: 15000\n",
      "time: 12.073819398880005  count: 16000\n",
      "time: 12.335830688476562  count: 17000\n",
      "time: 11.697640180587769  count: 18000\n",
      "time: 12.603720903396606  count: 19000\n",
      "time: 12.044790506362915  count: 20000\n",
      "time: 10.525394201278687  count: 21000\n",
      "time: 10.050683975219727  count: 22000\n",
      "time: 11.899126768112183  count: 23000\n",
      "time: 11.846455335617065  count: 24000\n",
      "time: 10.586645364761353  count: 25000\n",
      "time: 12.133596897125244  count: 26000\n",
      "time: 9.788665056228638  count: 27000\n",
      "time: 8.77630352973938  count: 28000\n",
      "time: 11.108652353286743  count: 29000\n",
      "time: 9.29899525642395  count: 30000\n",
      "time: 8.131813526153564  count: 31000\n",
      "time: 8.894354820251465  count: 32000\n",
      "time: 12.37432050704956  count: 33000\n",
      "time: 7.808954477310181  count: 34000\n",
      "time: 7.941628694534302  count: 35000\n",
      "time: 10.267624855041504  count: 36000\n",
      "time: 8.453442811965942  count: 37000\n",
      "time: 10.05301833152771  count: 38000\n",
      "time: 8.793598651885986  count: 39000\n",
      "time: 10.400083780288696  count: 40000\n",
      "time: 7.682428359985352  count: 41000\n",
      "time: 8.213168621063232  count: 42000\n",
      "time: 11.412482500076294  count: 43000\n",
      "time: 8.707566261291504  count: 44000\n",
      "time: 8.02009630203247  count: 45000\n",
      "time: 8.045879125595093  count: 46000\n",
      "time: 9.501078844070435  count: 47000\n",
      "time: 7.770918846130371  count: 48000\n",
      "time: 8.169719696044922  count: 49000\n",
      "time: 8.926843404769897  count: 50000\n",
      "time: 9.74822998046875  count: 51000\n",
      "time: 6.555929183959961  count: 52000\n",
      "time: 8.067629337310791  count: 53000\n",
      "time: 8.084633827209473  count: 54000\n",
      "time: 10.004342794418335  count: 55000\n",
      "time: 7.856613397598267  count: 56000\n",
      "time: 8.123029708862305  count: 57000\n",
      "time: 8.658063650131226  count: 58000\n",
      "time: 9.630893230438232  count: 59000\n",
      "time: 7.653128623962402  count: 60000\n",
      "time: 8.164822578430176  count: 61000\n",
      "time: 8.797566413879395  count: 62000\n",
      "time: 8.291775941848755  count: 63000\n",
      "time: 8.04925537109375  count: 64000\n",
      "time: 8.506189346313477  count: 65000\n",
      "time: 10.95771312713623  count: 66000\n",
      "time: 7.351006031036377  count: 67000\n",
      "time: 7.488478899002075  count: 68000\n",
      "time: 9.657930850982666  count: 69000\n",
      "time: 10.078916072845459  count: 70000\n",
      "time: 7.4690022468566895  count: 71000\n",
      "time: 8.133487224578857  count: 72000\n",
      "time: 8.533123970031738  count: 73000\n",
      "time: 9.47664999961853  count: 74000\n",
      "time: 7.935559034347534  count: 75000\n",
      "time: 7.936443567276001  count: 76000\n",
      "time: 7.421195030212402  count: 77000\n",
      "time: 10.084851026535034  count: 78000\n",
      "time: 7.899816274642944  count: 79000\n",
      "time: 7.024080038070679  count: 80000\n",
      "time: 7.249448776245117  count: 81000\n",
      "time: 9.525150060653687  count: 82000\n",
      "time: 7.0800535678863525  count: 83000\n",
      "time: 7.291053056716919  count: 84000\n",
      "time: 7.127345085144043  count: 85000\n",
      "time: 11.072758436203003  count: 86000\n",
      "time: 8.476456880569458  count: 87000\n",
      "time: 6.555356502532959  count: 88000\n",
      "time: 7.437634706497192  count: 89000\n",
      "time: 9.70185112953186  count: 90000\n",
      "time: 7.41411566734314  count: 91000\n",
      "time: 6.791863918304443  count: 92000\n",
      "time: 7.763757705688477  count: 93000\n",
      "time: 10.760865449905396  count: 94000\n",
      "time: 8.289317607879639  count: 95000\n",
      "time: 6.7506866455078125  count: 96000\n",
      "time: 7.14838719367981  count: 97000\n",
      "time: 10.034961223602295  count: 98000\n",
      "time: 8.622971773147583  count: 99000\n",
      "time: 6.736122369766235  count: 100000\n",
      "time: 6.962104082107544  count: 101000\n",
      "time: 7.514451742172241  count: 102000\n",
      "time: 10.299906492233276  count: 103000\n",
      "time: 8.237797975540161  count: 104000\n",
      "time: 7.880961179733276  count: 105000\n",
      "time: 9.844894409179688  count: 106000\n",
      "time: 8.546481132507324  count: 107000\n",
      "time: 8.704168319702148  count: 108000\n",
      "time: 7.344848394393921  count: 109000\n",
      "time: 9.523374795913696  count: 110000\n",
      "time: 8.907413244247437  count: 111000\n",
      "time: 23.584630012512207  count: 112000\n",
      "time: 7.0646071434021  count: 113000\n",
      "time: 6.461396217346191  count: 114000\n",
      "time: 8.127644538879395  count: 115000\n",
      "time: 9.173459768295288  count: 116000\n",
      "time: 7.150416374206543  count: 117000\n",
      "time: 6.67113995552063  count: 118000\n",
      "time: 9.35042119026184  count: 119000\n",
      "time: 35.60696053504944  count: 120000\n",
      "time: 44.333606481552124  count: 121000\n",
      "time: 44.246965408325195  count: 122000\n",
      "time: 37.153340578079224  count: 123000\n",
      "time: 26.17804741859436  count: 124000\n",
      "time: 16.095215320587158  count: 125000\n",
      "time: 10.093717336654663  count: 126000\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 387M Sep 11 18:49 nsfw_dataset_test.rec\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 3.6G Sep 12 07:39 nsfw_dataset_train.rec\n",
      "-rw-rw-r-- 1 ec2-user ec2-user 318M Sep 12 07:16 nsfw_dataset_valid.rec\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "echo \"Creating LST files\"\n",
    "python $IM2REC --list --recursive --pass-through --test-ratio=0.0 --train-ratio=1.0 nsfw_dataset_train nsfw_dataset_train > nsfw_dataset_train_classes\n",
    "\n",
    "echo \"Label classes:\"\n",
    "cat nsfw_dataset_train_classes\n",
    "\n",
    "echo \"Creating RecordIO files\"\n",
    "python $IM2REC --num-thread=4 nsfw_dataset_train.lst nsfw_dataset_train/ --resize=224\n",
    "#python $IM2REC --num-thread=4 ${DATASET_NAME}_test.lst $DATASET_NAME\n",
    "ls -lh *.rec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upload: ./nsfw_dataset_train.rec to s3://project-completion-udacity/nsfw_dataset/training/nsfw_dataset_train.rec\n"
     ]
    }
   ],
   "source": [
    "!aws s3 cp nsfw_dataset_train.rec s3://project-completion-udacity/nsfw_dataset/training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
